{
 "cells": [
  {
   "cell_type": "code",
   "id": "03e16184-a721-407e-a2f6-fc452835e0b4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-22T07:43:35.271212Z",
     "start_time": "2025-11-22T07:43:32.241344Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"TORCH_CUDA_ARCH_LIST\"] = \"8.9\" # for RTX 4060\n",
    "\n",
    "import mitsuba as mi\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "import drjit as dr\n",
    "dr.set_flag(dr.JitFlag.LoopRecord, False)\n",
    "dr.set_flag(dr.JitFlag.VCallRecord, False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.neubsdf import *\n",
    "from models.neureparam import NeuReparam\n",
    "from models.neumip import NeuBTF, NeuMIP\n",
    "from utils import binning2d, angle2xyz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "25749ba2-88e4-4efb-bce8-fde4f1020b14",
   "metadata": {},
   "source": [
    "## Demo scene in mitsuba dict"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ecb1458-4e74-4552-8945-722b844e526d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-22T07:43:35.349079Z",
     "start_time": "2025-11-22T07:43:35.344492Z"
    }
   },
   "source": [
    "def get_scene(bsdf,integrator,width=800,height=800):\n",
    "    fac = 7\n",
    "    rad = 2.\n",
    "    r = 0.01\n",
    "    return {\n",
    "        'type': 'scene',\n",
    "        'camera': {\n",
    "            'type': 'perspective',\n",
    "            'fov': 30,\n",
    "            'to_world': mi.ScalarTransform4f.look_at(\n",
    "                origin=[0,3.1,6.08],\n",
    "                target=[0,0.0,0.0],\n",
    "                up=[0,1,0]\n",
    "            ),\n",
    "            'film': {\n",
    "                'type': 'hdrfilm',\n",
    "                'width': width, 'height': height\n",
    "            }\n",
    "        },\n",
    "\n",
    "        'bkgd': {\n",
    "            'type': 'constant',\n",
    "            'radiance': {\n",
    "                'type': 'rgb',\n",
    "                'value': 0.1\n",
    "            }\n",
    "        },\n",
    "        'bsdf-mat': bsdf,\n",
    "\n",
    "        'l1': {\n",
    "            'type':'sphere',\n",
    "            'radius': r,\n",
    "            'center': [-1.2,1.2,0.1],\n",
    "            'bsdf': {'type':'null'},\n",
    "            'emitter': {\n",
    "                'type':'area',\n",
    "                'radiance': {\n",
    "                    'type': 'rgb',\n",
    "                    'value': rad*fac**4,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'l2': {\n",
    "            'type':'sphere',\n",
    "            'radius': r*fac,\n",
    "            'center': [0.0,1.2,0.1],\n",
    "            'bsdf': {'type':'null'},\n",
    "            'emitter': {\n",
    "                'type':'area',\n",
    "                'radiance': {\n",
    "                    'type': 'rgb',\n",
    "                    'value': rad*fac**2,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'l3': {\n",
    "            'type':'sphere',\n",
    "            'radius': r*fac*fac,\n",
    "            'center': [1.2,1.2,0.1],\n",
    "            'bsdf': {'type':'null'},\n",
    "            'emitter': {\n",
    "                'type':'area',\n",
    "                'radiance': {\n",
    "                    'type': 'rgb',\n",
    "                    'value': rad,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "\n",
    "        'demo-material': {\n",
    "            'type': 'cube',\n",
    "            'to_world': mi.ScalarTransform4f.translate([0,-0.5,0]).rotate([1,0,0],35).scale([1.5,0.1,0.9]).rotate([0,1,0],90),\n",
    "            #'type':'sphere',\n",
    "            #'to_world': mi.ScalarTransform4f.translate([0,-0.5,0]).rotate([1,0,0],35).scale([0.9,0.9,0.9]),\n",
    "            'bsdf': {\n",
    "                'type': 'ref',\n",
    "                'id': 'bsdf-mat'\n",
    "            }\n",
    "        },\n",
    "\n",
    "        'bsdf-plane':{\n",
    "                'type': 'diffuse',\n",
    "                'reflectance': {\n",
    "                    'type':'rgb','value':[0.4,0.4,0.4]\n",
    "                }\n",
    "            },\n",
    "        'plane': {\n",
    "            'type': 'rectangle',\n",
    "            'to_world': mi.ScalarTransform4f.translate([0,-1.5,0]).rotate([1,0,0],-90).scale([4,2.5,1]),\n",
    "            'bsdf': {\n",
    "                'type': 'ref',\n",
    "                'id': 'bsdf-plane'\n",
    "            }\n",
    "        },\n",
    "        'plane2': {\n",
    "            'type': 'rectangle',\n",
    "            'to_world': mi.ScalarTransform4f.translate([0,-0,-1.75]).rotate([1,0,0],0).scale([4,1.5,1]),\n",
    "            'bsdf': {\n",
    "                'type': 'ref',\n",
    "                'id': 'bsdf-plane'\n",
    "            }\n",
    "        },\n",
    "\n",
    "        'integrator': integrator\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "57f90654-03b3-4ec6-8571-c43b5fad18ee",
   "metadata": {},
   "source": [
    "## Specify neural BRDF and integrator"
   ]
  },
  {
   "cell_type": "code",
   "id": "3316f054-6a58-45b2-80a5-7af84ff042b1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-22T07:43:35.532090Z",
     "start_time": "2025-11-22T07:43:35.354902Z"
    }
   },
   "source": [
    "weight_path = '../notebooks/weights'\n",
    "# mat = 'aniso_metallic_paper_copper'\n",
    "# dataset = 'rgl'\n",
    "mat = 'melted_metal'\n",
    "dataset = 'neusample'\n",
    "\n",
    "bsdf = {\n",
    "    'type': 'neubsdf',\n",
    "    'brdf_ckpt': f'{weight_path}/{dataset}/brdf/{mat}.pth',\n",
    "    'mode':'reparam',\n",
    "    'sampler_ckpt': f'{weight_path}/{dataset}/sampler/{mat}.pth', \n",
    "    'uv_scale': 1\n",
    "}\n",
    "\n",
    "integrator = {\n",
    "    'type': 'path',\n",
    "    'max_depth': 3\n",
    "}\n",
    "\n",
    "scene = mi.load_dict(get_scene(bsdf,integrator))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3cbf9ed2-641f-4bde-9b1c-ce394debd195",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Render the scene"
   ]
  },
  {
   "cell_type": "code",
   "id": "d985af05-7a40-4d11-a020-a222050e7bad",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-11-22T07:43:35.900504Z",
     "start_time": "2025-11-22T07:43:35.541337Z"
    }
   },
   "source": [
    "spp = 8\n",
    "img = mi.render(scene,spp=8).torch()\n",
    "plt.imshow(img.pow(1/2.2).cpu())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== eval_pdf(): information ===\n",
      "uv_ shape: torch.Size([2, 1893959])\n",
      "wi_ shape: torch.Size([3, 2])\n",
      "============================\n",
      "=== eval_texture(): information ===\n",
      "f_offset shape: torch.Size([2, 8])\n",
      "f_offset shape: tensor([-0.2169, -0.3081, -0.2028,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "============================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "drjit.custom(<mitsuba.python.util._RenderOp>): error while performing a custom differentiable operation. (see above).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\python3.13.2\\Lib\\site-packages\\mitsuba\\python\\util.py:366\u001B[39m, in \u001B[36m_RenderOp.eval\u001B[39m\u001B[34m(self, scene, sensor, _, params, integrator, seed, spp)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m dr.suspend_grad():\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     res = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mintegrator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    367\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscene\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mscene\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    368\u001B[39m \u001B[43m        \u001B[49m\u001B[43msensor\u001B[49m\u001B[43m=\u001B[49m\u001B[43msensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    369\u001B[39m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m=\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[43m        \u001B[49m\u001B[43mspp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mspp\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    371\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdevelop\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    372\u001B[39m \u001B[43m        \u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    373\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    374\u001B[39m     \u001B[38;5;66;03m# After rendering an image, the sampler state is dependent on the\u001B[39;00m\n\u001B[32m    375\u001B[39m     \u001B[38;5;66;03m# rendering loop. When a frozen function is recorded, the sampler\u001B[39;00m\n\u001B[32m    376\u001B[39m     \u001B[38;5;66;03m# might be evaluated, which causes parts of the rendering loop to\u001B[39;00m\n\u001B[32m    377\u001B[39m     \u001B[38;5;66;03m# be re-evaluated. To prevent this overhead, we reset the state\u001B[39;00m\n\u001B[32m    378\u001B[39m     \u001B[38;5;66;03m# of the sampler, by re-seeding it.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\GitHub\\Repository\\reparam25\\models\\neubsdf.py:166\u001B[39m, in \u001B[36mNeuBSDF.eval_pdf\u001B[39m\u001B[34m(self, ctx, si, wo, active)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m============================\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m166\u001B[39m f_rgb_ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mneumip\u001B[49m\u001B[43m.\u001B[49m\u001B[43meval_texture\u001B[49m\u001B[43m(\u001B[49m\u001B[43muv_\u001B[49m\u001B[43m,\u001B[49m\u001B[43mwi_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    167\u001B[39m cond_ = \u001B[38;5;28mself\u001B[39m.neusampler.encode_cond(wi_,f_rgb_)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mF:\\GitHub\\Repository\\reparam25\\models\\neumip.py:102\u001B[39m, in \u001B[36mNeuMIP.eval_texture\u001B[39m\u001B[34m(self, uv, wo)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m============================\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m102\u001B[39m r = mlp_fused32(\u001B[32m1\u001B[39m,\u001B[32m2\u001B[39m,\u001B[32m1\u001B[39m,\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mf_offset\u001B[49m\u001B[43m,\u001B[49m\u001B[43mwo\u001B[49m\u001B[43m[\u001B[49m\u001B[43m.\u001B[49m\u001B[43m.\u001B[49m\u001B[43m.\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m.half(),\u001B[38;5;28mself\u001B[39m.offset_params).float()\n\u001B[32m    103\u001B[39m uv_offset = (r/(\u001B[32m1\u001B[39m-wo.pow(\u001B[32m2\u001B[39m).sum(-\u001B[32m1\u001B[39m,keepdim=\u001B[38;5;28;01mTrue\u001B[39;00m)).clamp_min(\u001B[32m0.36\u001B[39m).sqrt())*wo\n",
      "\u001B[31mRuntimeError\u001B[39m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m spp = \u001B[32m8\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m img = \u001B[43mmi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscene\u001B[49m\u001B[43m,\u001B[49m\u001B[43mspp\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m8\u001B[39;49m\u001B[43m)\u001B[49m.torch()\n\u001B[32m      3\u001B[39m plt.imshow(img.pow(\u001B[32m1\u001B[39m/\u001B[32m2.2\u001B[39m).cpu())\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\python3.13.2\\Lib\\site-packages\\mitsuba\\python\\util.py:524\u001B[39m, in \u001B[36mrender\u001B[39m\u001B[34m(scene, params, sensor, integrator, seed, seed_grad, spp, spp_grad)\u001B[39m\n\u001B[32m    511\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m integrator.render(\n\u001B[32m    512\u001B[39m             scene=scene,\n\u001B[32m    513\u001B[39m             sensor=sensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    517\u001B[39m             evaluate=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    518\u001B[39m         )\n\u001B[32m    520\u001B[39m \u001B[38;5;66;03m# Both `dict_params` and `params` are passed. The former is necessary\u001B[39;00m\n\u001B[32m    521\u001B[39m \u001B[38;5;66;03m# because it allows the custom operation to detect any attached input\u001B[39;00m\n\u001B[32m    522\u001B[39m \u001B[38;5;66;03m# arguments. The latter is necessary because it will not be automatically\u001B[39;00m\n\u001B[32m    523\u001B[39m \u001B[38;5;66;03m# detached by the custom operation.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m524\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcustom\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_RenderOp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscene\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintegrator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    525\u001B[39m \u001B[43m                 \u001B[49m\u001B[43m(\u001B[49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed_grad\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mspp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspp_grad\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: drjit.custom(<mitsuba.python.util._RenderOp>): error while performing a custom differentiable operation. (see above)."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "cb4bc6c0-265e-4a4b-9a2d-f250d8641286",
   "metadata": {},
   "source": [
    "## Visualize the sampling"
   ]
  },
  {
   "cell_type": "code",
   "id": "d7cc1896-f979-48a6-8250-d924ab0f9e3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "device = torch.device(0)\n",
    "model = NeuReparam(16,2,16,1,4,T=0 if dataset == 'rgl' else 8)\n",
    "\n",
    "weight = torch.load(f'{weight_path}/{dataset}/sampler/{mat}.pth',map_location='cpu')\n",
    "model.load_state_dict(weight)\n",
    "model.to(device)\n",
    "model.requires_grad_(False)\n",
    "model.prepare()\n",
    "\n",
    "if dataset == 'rgl':\n",
    "    brdf = NeuBTF()\n",
    "else:\n",
    "    brdf = NeuMIP()\n",
    "weight = torch.load(f'{weight_path}/{dataset}/brdf/{mat}.pth',map_location='cpu')\n",
    "brdf.load_state_dict(weight)\n",
    "brdf.to(device)\n",
    "brdf.requires_grad_(False)\n",
    "brdf.prepare()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03f4e8cf-7e7b-482a-ae5c-267470676927",
   "metadata": {
    "tags": []
   },
   "source": [
    "# random viewing direction and uv cooridnates\n",
    "wo = angle2xyz(torch.tensor(30),torch.tensor(20))[None,:2].to(device)\n",
    "uv = torch.tensor([0.5,0.5],device=device)[None]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7c529902-52ef-4db1-8a41-482438888344",
   "metadata": {
    "tags": []
   },
   "source": [
    "res = 128\n",
    "grid = torch.stack(torch.meshgrid(*[torch.linspace(-1,1,res,device=device)]*2,indexing='xy'),-1).reshape(-1,2)\n",
    "valid = grid.norm(dim=-1)<=1\n",
    "\n",
    "f_rgb = brdf.eval_texture(uv,wo)\n",
    "rgb = brdf.eval(f_rgb if f_rgb is None else f_rgb.expand(len(grid),-1),wo.expand(len(grid),-1),grid)\n",
    "rgb[~valid] = 0\n",
    "rgb = rgb.reshape(res,res,3).cpu()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d77ad0f-bd02-4398-9073-d793b0ebc627",
   "metadata": {
    "tags": []
   },
   "source": [
    "cond = model.encode_cond(wo,f_rgb)\n",
    "pdf = torch.zeros(res,res,device=device)\n",
    "for _ in tqdm(range(8)):\n",
    "    sample2 = torch.rand(1000_000,2,device=device)\n",
    "    wi = model.sample_cond(cond.expand(len(sample2),-1),sample2)[0]\n",
    "    pdf += binning2d(*wi[...,:2].T,res,-1,1,-1,1)\n",
    "pdf /= pdf.sum()\n",
    "pdf = pdf.cpu()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b83d25fb-9a51-407a-9a5e-57f46c5206dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pdf.pow(1/4.2))\n",
    "plt.title('samples')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(rgb.mean(-1).pow(1/4.2))\n",
    "plt.title('reference')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
